{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Koushouu/Bioimage-Analysis-Workshop-Taipei/blob/main/Cellpose_2_0_in_colab_part_1_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running cellpose 2.0 in colab - part 1\n",
        "\n",
        "In this notebook we will run cellpose segmentation on our sample images, with the model provided by cellpose. There is also an option to segment with our own custom model, the methods to make your own model will be covered in another notebook. \n",
        "\n",
        "If your notebook is in Chinese please go to \"説明\" tab above and select \"查看英文版本\"\n",
        "\n",
        "There are two sections in this notebook:\n",
        "\n",
        "* Section 1 - Setup: we will install cellpose 2.0 and openCV to our runtime. And we will initialize the colab cloud GPU\n",
        "\n",
        "* Section 2 - Cellpose segmentation with pretrained or custom models: We will segment our custom image in this section, and we will show the segmentation result with matplotlib\n",
        "\n",
        "The content of this notebook is mostly modified from: https://colab.research.google.com/github/MouseLand/cellpose/blob/main/notebooks/run_cellpose_2.ipynb"
      ],
      "metadata": {
        "id": "k5nTfxj7CY98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "We will first install cellpose 2.0, check the GPU is working, and mount google drive to get your models and images."
      ],
      "metadata": {
        "id": "ZzkMDBEqETqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "hYw3qJVCEbp4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j8EZePlhcvD"
      },
      "source": [
        "Install cellpose -- by default the torch GPU version is installed in COLAB notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOJDKjgzhDjJ"
      },
      "outputs": [],
      "source": [
        "!pip install \"opencv-python-headless<4.3\"\n",
        "!pip install cellpose"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check CUDA version and that GPU is working in cellpose and import other libraries. If your GPU activation failed its probably due to the wrong runtime type during setup. Go to Runtime tab above -> Change Runtime Type -> Hardware Accelerator -> GPU"
      ],
      "metadata": {
        "id": "XqjcRrgjEsNG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEsVTBTmk8O_"
      },
      "outputs": [],
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi\n",
        "\n",
        "import os, shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from cellpose import core, utils, io, models, metrics\n",
        "from glob import glob\n",
        "\n",
        "use_GPU = core.use_gpu()\n",
        "yn = ['NO', 'YES']\n",
        "print(f'>>> GPU activated? {yn[use_GPU]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect your Google Drive to Colab\n",
        "\n",
        "Mount your google drive and find your working folder with (if available) the model that you trained. If you want to train a model, create a folder in google drive with the images and the labels ( `_seg.npy` files from the cellpose gui)"
      ],
      "metadata": {
        "id": "Keq6PR1sJL2_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTCOjJrHlaf7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use pretrained or custom model to segment images\n",
        "\n",
        "## Model parameters:\n",
        "\n",
        "<font size = 4>**`initial_model`:** Choose a model from the cellpose [model zoo](https://cellpose.readthedocs.io/en/latest/models.html#model-zoo) to start from.\n",
        "\n",
        "<font size = 4>**`moodel_path`:** Full path to the custum trained model\n",
        "\n",
        "You should leave one of them empty"
      ],
      "metadata": {
        "id": "PGTvs1ZyU4Pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model name and path\n",
        "\n",
        "#@markdown ###Pretrained model name from model zoo:\n",
        "\n",
        "initial_model = \"cyto2\" #@param ['cyto','nuclei','tissuenet','livecell','cyto2','CP','CPx','TN1','TN2','TN3','LC1','LC2','LC3','LC4','scratch'] {type:\"string\"}\n",
        "\n",
        "#@markdown ###or Custom model path (full path):\n",
        "\n",
        "model_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ###Path to images:\n",
        "\n",
        "dir = \"/content/gdrive/MyDrive/Colab Notebooks/example_data\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ###Channel Parameters:\n",
        "\n",
        "Channel_to_use_for_segmentation = \"Grayscale\" #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
        "\n",
        "# @markdown If you have a secondary channel that can be used, for instance nuclei, choose it here:\n",
        "\n",
        "Second_segmentation_channel= \"None\" #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
        "\n",
        "\n",
        "# Here we match the channel to number\n",
        "if Channel_to_use_for_segmentation == \"Grayscale\":\n",
        "  chan = 0\n",
        "elif Channel_to_use_for_segmentation == \"Blue\":\n",
        "  chan = 3\n",
        "elif Channel_to_use_for_segmentation == \"Green\":\n",
        "  chan = 2\n",
        "elif Channel_to_use_for_segmentation == \"Red\":\n",
        "  chan = 1\n",
        "\n",
        "\n",
        "if Second_segmentation_channel == \"Blue\":\n",
        "  chan2 = 3\n",
        "elif Second_segmentation_channel == \"Green\":\n",
        "  chan2 = 2\n",
        "elif Second_segmentation_channel == \"Red\":\n",
        "  chan2 = 1\n",
        "elif Second_segmentation_channel == \"None\":\n",
        "  chan2 = 0\n",
        "\n",
        "#@markdown ### Segmentation parameters:\n",
        "\n",
        "#@markdown diameter of cells (set to zero to use diameter from training set):\n",
        "diameter =  40#@param {type:\"number\"}\n",
        "#@markdown threshold on flow error to accept a mask (set higher to get more cells, e.g. in range from (0.1, 3.0), OR set to 0.0 to turn off so no cells discarded):\n",
        "flow_threshold = 0.4 #@param {type:\"slider\", min:0.0, max:3.0, step:0.1}\n",
        "#@markdown threshold on cellprob output to seed cell masks (set lower to include more pixels or higher to include fewer, e.g. in range from (-6, 6)):\n",
        "cellprob_threshold=0 #@param {type:\"slider\", min:-6, max:6, step:1}"
      ],
      "metadata": {
        "id": "SdWKkVHhVJ_e",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## run model"
      ],
      "metadata": {
        "id": "qT4znfK4Wo8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gets image files in dir (ignoring image files ending in _masks)\n",
        "files = io.get_image_files(dir, '_masks')\n",
        "print(files)\n",
        "images = [io.imread(f) for f in files]\n",
        "\n",
        "# set channels\n",
        "channels = [chan, chan2]\n",
        "\n",
        "# declare model\n",
        "if model_path ==\"\":\n",
        "  model = models.CellposeModel(gpu=True, \n",
        "                             model_type=initial_model)\n",
        "else: \n",
        "  model = models.CellposeModel(gpu=True, \n",
        "                             pretrained_model=model_path)\n",
        "\n",
        "# use model diameter if user diameter is 0\n",
        "diameter = model.diam_labels if diameter==0 else diameter\n",
        "\n",
        "# run model on test images\n",
        "masks, flows, styles = model.eval(images, \n",
        "                                  channels=[chan, chan2],\n",
        "                                  diameter=diameter,\n",
        "                                  flow_threshold=flow_threshold,\n",
        "                                  cellprob_threshold=cellprob_threshold\n",
        "                                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrBtCDQiWxDW",
        "outputId": "a059a860-b3fe-4c6e-caa4-9727c9137155"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/gdrive/MyDrive/Colab Notebooks/example_data/example_cells_1.tif', '/content/gdrive/MyDrive/Colab Notebooks/example_data/example_cells_2.tif']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25.3M/25.3M [00:03<00:00, 7.90MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show results with matplotlib"
      ],
      "metadata": {
        "id": "YwdI8_lFFfzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.io import imread\n",
        "# read both the images and the segmentation results\n",
        "image_id = 1\n",
        "# Show the image\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(images[image_id], interpolation='none', cmap='gray')\n",
        "plt.imshow(np.ma.array(masks[image_id], mask=masks[image_id]==0), cmap = 'prism', alpha = 0.4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8TDF96rnFm2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save output to *_seg.npy\n",
        "\n",
        "you will see the files save in the folder where your test image is located (Might need to wait for a min or two to have it appear on your drive folder)"
      ],
      "metadata": {
        "id": "WRLurc1NaAKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cellpose import io\n",
        "\n",
        "io.masks_flows_to_seg(images, \n",
        "                      masks, \n",
        "                      flows, \n",
        "                      diameter*np.ones(len(masks)), \n",
        "                      files, \n",
        "                      channels)"
      ],
      "metadata": {
        "id": "w5eY_aVPZ8xs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save output masks\n",
        "\n",
        "Output masks (segmentations) can be saved in png/tif/txt for futher processing in imageJ or other python scripts."
      ],
      "metadata": {
        "id": "_jn_B5LCcODo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "io.save_masks(images, \n",
        "              masks, \n",
        "              flows, \n",
        "              files, \n",
        "              channels=channels,\n",
        "              png=False, # save masks as PNGs and save example image\n",
        "              tif=True, # save masks as TIFFs\n",
        "              save_txt=False, # save txt outlines for ImageJ\n",
        "              save_flows=False, # save flows as TIFFs\n",
        "              save_outlines=False, # save outlines as TIFFs \n",
        "              )"
      ],
      "metadata": {
        "id": "5K2REZ4acOxR"
      },
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp5mHs/hd5NNKW5DKfQEAG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}