{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis with Python - <font color='teal'>Tutorial Pipeline Section 2</font>\n",
    "\n",
    "*originally created in 2016*<br>\n",
    "*updated and converted to a Jupyter notebook in 2017*<br>\n",
    "*updated and converted to python 3 in 2018*<br>\n",
    "*by Jonas Hartmann (Gilmour group, EMBL Heidelberg)*<br>\n",
    "*updated in 2022 by Cheng-Yu Huang*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Table of Contents\n",
    "\n",
    "1. [About this Tutorial](#about)\n",
    "2. [Initialization](#initialize)\n",
    "11. [Postprocessing: Removing Cells at the Image Border](#postpro)\n",
    "12. [Identifying Cell Edges](#edges)\n",
    "13. [Extracting Quantitative Measurements](#measure)\n",
    "14. [Simple Analysis & Visualization](#analysis)\n",
    "15. [Writing Output to Files](#write)\n",
    "16. [BONUS - Batch Processing](#batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  About this Tutorial <a id=about></a>\n",
    "\n",
    "*This tutorial covers the part 2 of the image analysis tutorial*\n",
    "\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- In the section 1 of the Codelab, you performed adaptive thresholding and connected-component analysis of our raw image.\n",
    "\n",
    "- Here we are going to continue from where we left behind, starting with the segmentation result, we will first clean all the cell patches near the border of the image, and detect the edge of each cells. Then we will perform the statistical analysis to the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization <a id=initialize></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will import all the necessary modules and packages. Then we will load the raw image data and our segmentation results, for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Importing all the necessary modules and packages\n",
    "\n",
    "# The numerical arrays manipulation module numpy as np\n",
    "# The plotting module matplotlib.pyplot as plt\n",
    "# The image processing module scipy.ndimage as ndi\n",
    "### YOUR CODE HERE!\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Set matplotlib backend\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Specify the directory path and file name\n",
    "\n",
    "# Create a string variable with the relative (or absolute) path to your raw image\n",
    "# and segmentation results. \n",
    "### YOUR CODE HERE!\n",
    "img_filepath = r'example_data\\example_cells_1.tif'\n",
    "seg_filepath = r'example_cells_1_seg.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iv) Load the raw image and the segmentation results\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "from skimage.io import imread\n",
    "img = imread(img_filepath)\n",
    "seg = imread(seg_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (v) Look at the images to confirm that everything worked as intended\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,7))\n",
    "ax[0].imshow(img, interpolation='none', cmap='gray')\n",
    "ax[1].imshow(seg, interpolation='none', cmap='prism')\n",
    "ax[0].set_title('Raw Image')\n",
    "ax[1].set_title('Segmentation Result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing: Removing Cells at the Image Border <a id=postpro></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "Since segmentation is never perfect, it often makes sense to explicitely remove artifacts afterwards. For example, one could filter out objects that are too small, have a very strange shape, or very strange intensity values. \n",
    "\n",
    "**Warning:** Filtering out objects is equivalent to the *removal of outliers* in data analysis and *should only be done for good reason and with caution!*\n",
    "\n",
    "As an example of postprocessing, we will now filter out a particular group of problematic cells: those that are being cut off at the image border."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'> Exercise </font>\n",
    "\n",
    "Iterate through all the cells in your segmentation and remove those touching the image border.\n",
    "\n",
    "Follow the instructions in the comments below. Note that the instructions will get a little less specific from here on, so you need to figure out how to approach a problem yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Create an image border mask\n",
    "\n",
    "# We need some way to check if a cell is at the border. For this, we generate a 'mask' of the image border,\n",
    "# i.e. a Boolean array of the same size as the image where only the border pixels are set to `1` and all \n",
    "# others to `0`, like this:\n",
    "#   1 1 1 1 1\n",
    "#   1 0 0 0 1\n",
    "#   1 0 0 0 1\n",
    "#   1 0 0 0 1\n",
    "#   1 1 1 1 1\n",
    "# There are multiple ways of generating this mask, for example by erosion or by array indexing.\n",
    "# It is up to you to find a way to do it. (Hint: one of the the easiest ways to do this is via scipy.ndimage.binary_dilation.\n",
    "# check the parameter \"border_value\")\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "border_mask = np.zeros(seg.shape, dtype=bool)\n",
    "border_mask = ndi.binary_dilation(border_mask, border_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) 'Delete' the cells at the border\n",
    "\n",
    "# When modifying a segmentation (in this case by deleting some cells), it makes sense\n",
    "# to work on a copy of the array, not on the original. This avoids unexpected behaviors,\n",
    "# especially within jupyter notebooks. Use the function 'np.copy' to copy an array.\n",
    "### YOUR CODE HERE!\n",
    "clean_seg = np.copy(seg)\n",
    "\n",
    "# Iterate over the IDs of all the cells in the segmentation. Use a for-loop and the \n",
    "# function 'np.unique' (remember that each cell in our segmentation is labeled with a \n",
    "# different integer value).\n",
    "### YOUR CODE HERE!\n",
    "for cell_ID in np.unique(seg):\n",
    "\n",
    "    # Create a mask that contains only the 'current' cell of the iteration\n",
    "    # Hint: Remember that the comparison of an array with some number (array==number)\n",
    "    #       returns a Boolean mask of the pixels in 'array' whose value is 'number'.\n",
    "    ### YOUR CODE HERE!\n",
    "    cell_mask = seg==cell_ID\n",
    "    \n",
    "    # Using the cell mask and the border mask from above, test if the cell has pixels touching \n",
    "    # the image border or not.\n",
    "    # Hint: 'np.logical_and'\n",
    "    ### YOUR CODE HERE!\n",
    "    cell_border_overlap = np.logical_and(cell_mask, border_mask)  # Overlap of cell mask and boundary mask\n",
    "    total_overlap_pixels = np.sum(cell_border_overlap)            # Sum overlapping pixels\n",
    "    \n",
    "    # If a cell touches the image boundary, delete it by setting its pixels in the segmentation to 0.\n",
    "    ### YOUR CODE HERE!\n",
    "    if total_overlap_pixels > 0: \n",
    "        clean_seg[cell_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: re-label the remaining cells to keep the numbering consistent from 1 to N (with 0 as background).\n",
    "# Hint: Use python function <enumerate>\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "for new_ID, cell_ID in enumerate(np.unique(clean_seg)[1:]):  # The [1:] excludes 0 from the list (background)!\n",
    "    clean_seg[clean_seg==cell_ID] = new_ID+1                  # The same here for the +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Visualize the result\n",
    "\n",
    "# Show the result as transparent overlay over the raw or smoothed image. \n",
    "# Here you have to combine alpha (to make cells transparent) and 'np.ma.array'\n",
    "# (to hide empty space where the border cells were deleted).\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(img, interpolation='none', cmap='gray')\n",
    "plt.imshow(np.ma.array(clean_seg, mask=clean_seg==0), interpolation='none', cmap='prism', alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Cell Edges <a id=edges></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "With the final segmentation in hand, we can now start to think about measurements and data analysis. However, to extract interesting measurements from our cells, the segmentation on its own is often not enough: additional masks that identify sub-regions for each cell allow more precise and more biologically relevant measurements.\n",
    "\n",
    "The most useful example of this is an additional mask that identifies only the edge pixels of each cell. This is useful for a number of purposes, including:\n",
    "\n",
    "- Edge intensity is a good measure of membrane intensity, which is often a desired readout.\n",
    "- The intensity profile along the edge may contain information on cell polarity.\n",
    "- The length of the edge (relative to the cell area) is an informative feature about the cell shape. \n",
    "- Showing colored edges is a nice way of visualizing cell segmentations.\n",
    "\n",
    "There are many ways of identifying edge pixels in a fully labeled segmentation. Here, we will use a simple and relatively fast method based on erosion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'> Exercise </font>\n",
    "\n",
    "Create a labeled mask of cell edges by following these steps:\n",
    "\n",
    "\n",
    "- Create an array of the same size and data type as the segmentation but filled with only zeros\n",
    "    - This will be your final cell edge mask; you gradually add cell edges as you iterate over cells\n",
    "    \n",
    "\n",
    "- *For each cell...*\n",
    "    - Erode the cell's mask by 1 pixel\n",
    "    - Using the eroded mask and the original mask, create a new mask of only the cell's edge pixels\n",
    "    - Add the cell's edge pixels into the empty image generated above, labeling them with the cell's original ID number\n",
    "\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Create an array of the same size and data type as the segmentation but filled with only zeros\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "edges = np.zeros_like(clean_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Iterate over the cell IDs\n",
    "### YOUR CODE HERE!\n",
    "for cell_ID in np.unique(clean_seg)[1:]:\n",
    "    \n",
    "    # (iii) Erode the cell's mask by 1 pixel\n",
    "    # Hint: 'ndi.binary_erode'\n",
    "    ### YOUR CODE HERE!\n",
    "    cell_mask = clean_seg == cell_ID\n",
    "    eroded_cell_mask = ndi.binary_erosion(cell_mask, iterations=1) # Increase iterations to make boundary wider!\n",
    "    # (iv) Create the cell edge mask\n",
    "    # Hint: 'np.logical_xor'\n",
    "    ### YOUR CODE HERE!\n",
    "    edge_mask = np.logical_xor(cell_mask, eroded_cell_mask)\n",
    "    \n",
    "    # (v) Add the cell edge mask to the empty array generated above, labeling it with the cell's ID\n",
    "    ### YOUR CODE HERE!\n",
    "    edges[edge_mask] = cell_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vi) Visualize the result\n",
    "\n",
    "# Note: Because the lines are so thin (1pxl wide), they may not be displayed correctly in small figures.\n",
    "#       You can 'zoom in' by showing a sub-region of the image which is then rendered bigger. You can\n",
    "#       also go back to the edge identification code and make the edges multiple pixels wide (but keep \n",
    "#       in mind that this will have an effect on your quantification results!).\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(np.zeros_like(edges)[300:500, 300:500], cmap='gray', vmin=0, vmax=1)  # Simple black background\n",
    "plt.imshow(np.ma.array(edges, mask=edges==0)[300:500, 300:500], interpolation='none', cmap='prism')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Quantitative Measurements <a id=measure></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "The ultimate goal of image segmentation is of course the extraction of quantitative measurements, in this case on a single-cell level. Measures of interest can be based on intensity (in different channels) or on the size and shape of the cells.\n",
    "\n",
    "To exemplify how different properties of cells can be measured, we will extract the following:\n",
    "\n",
    "- Cell ID (so all other measurements can be traced back to the cell that was measured)\n",
    "- Mean intensity of each cell\n",
    "- Mean intensity at the membrane of each cell\n",
    "- The cell area, i.e. the number of pixels that make up the cell\n",
    "- The cell outline length, i.e. the number of pixels that make up the cell edge\n",
    "\n",
    "*Note: It makes sense to use smoothed/filtered/background-subtracted images for segmentation. When it comes to measurements, however, it's best to get back to the raw data!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'>Exercise</font>\n",
    "\n",
    "Extract the measurements listed above for each cell and collect them in a dictionary.\n",
    "\n",
    "Note: The ideal data structure for data like this is the `DataFrame` offered by the module `Pandas`. However, for the sake of simplicity, we will here stick with a dictionary of lists.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Create a dictionary that contains a key-value pairing for each measurement\n",
    "\n",
    "# The keys should be strings describing the type of measurement (e.g. 'intensity_mean') and \n",
    "# the values should be empty lists. These empty lists will be filled with the results of the\n",
    "# measurements.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "results = {\"cell_id\"      : [],\n",
    "           \"int_mean\"     : [],\n",
    "           \"int_mem_mean\" : [],\n",
    "           \"cell_area\"    : [],\n",
    "           \"cell_edge\"    : []}\n",
    "\n",
    "# Solution note: the spacing between the strings and colons doesn't matter for the code's\n",
    "# execution. It is used solely to make the code more readable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Record the measurements for each cell\n",
    "\n",
    "# Iterate over the segmented cells ('np.unique').\n",
    "# Inside the loop, create a mask for the current cell and use it to extract the measurements listed above. \n",
    "# Add them to the appropriate list in the dictionary using the 'append' method.\n",
    "# Hint: Remember that you can get out all the values within a masked area by indexing the image \n",
    "#       with the mask. For example, 'np.mean(image[cell_mask])' will return the mean of all the \n",
    "#       intensity values of 'image' that are masked by 'cell_mask'!\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "# Iterate over cell IDs\n",
    "for cell_id in np.unique(clean_seg)[1:]:\n",
    "\n",
    "    # Mask the current cell and cell edge\n",
    "    cell_mask = clean_seg==cell_id\n",
    "    edge_mask = edges==cell_id\n",
    "    \n",
    "    # Get the measurements\n",
    "    results[\"cell_id\"].append(cell_id)\n",
    "    results[\"int_mean\"].append(np.mean(img[cell_mask]))\n",
    "    results[\"int_mem_mean\"].append(np.mean(img[edge_mask]))\n",
    "    results[\"cell_area\"].append(np.sum(cell_mask))\n",
    "    results[\"cell_edge\"].append(np.sum(edge_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Print the results and check that they make sense\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "for key in results.keys(): \n",
    "    print(key + \":\", results[key][:5], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Analysis & Visualisation <a id=analysis></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "By extracting quantitative measurements from an image we cross over from 'image analysis' to 'data analysis'. \n",
    "\n",
    "This section briefly explains how to do basic data analysis and plotting, including boxplots, scatterplots and linear fits. It also showcases how to map data back onto the image, creating an \"image-based heatmap\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'>Exercise</font>\n",
    "\n",
    "Analyze and plot the extracted data in a variety of ways.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Familiarize yourself with the data structure of the results dict and summarize the results\n",
    "\n",
    "# Recall that dictionaries are unordered; a dataset of interest is accessed through its key.\n",
    "# In our case, the datasets inside the dict are lists of values, ordered in the same order\n",
    "# as the cell IDs. \n",
    "\n",
    "# For each dataset in the results dict, print its name (the key) along with its mean, standard \n",
    "# deviation, maximum, minimum, and median. The appropriate numpy methods (e.g. 'np.median') work\n",
    "# with lists just as well as with arrays.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "# Custom function for nice printing of summary statistics.\n",
    "# Note the use of format strings for nice number padding.\n",
    "def print_summary(data):\n",
    "    print( \"  Mean:    {:7.2f}\".format(np.mean(data))   )\n",
    "    print( \"  Stdev:   {:7.2f}\".format(np.std(data))    )\n",
    "    print( \"  Max:     {:7.2f}\".format(np.max(data))    )\n",
    "    print( \"  Min:     {:7.2f}\".format(np.min(data))    )\n",
    "    print( \"  Median:  {:7.2f}\".format(np.median(data)) )\n",
    "\n",
    "# Calling the custom function for each dataset\n",
    "for key in results.keys():\n",
    "    print( '\\n'+key )\n",
    "    print_summary(results[key])\n",
    "    \n",
    "# There are also pre-made functions to get summary statistics,\n",
    "# for example 'scipy.stats.describe'.\n",
    "from scipy.stats import describe\n",
    "stat_summary = describe(results['int_mean'])\n",
    "\n",
    "print( '\\nscipy.stats.describe of int_mean' )\n",
    "for key in stat_summary._asdict().keys():\n",
    "    print( ' ', key+': ', stat_summary._asdict()[key] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii)-1 Create a histogram showing the distribution of cell surface area in pixels \n",
    "\n",
    "# Use the function 'plt.hist'. Change the \"bins\" parameter of the function to see the more detailed \n",
    "# trend of the data. What do you observe?\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "num_bins = 30\n",
    "plt.hist(results['cell_area'], bins = num_bins)\n",
    "plt.xlabel('cell area [pxl]')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Cell Area Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii)-2 Create a box plot showing the mean cell and mean membrane intensities for both channels. \n",
    "\n",
    "# Use the function 'plt.boxplot'. Use the 'label' keyword of 'plt.boxplot' to label the x axis with \n",
    "# the corresponding key names. Feel free to play around with the various options of the boxplot \n",
    "# function to make your plot look nicer. Remember that you can first call 'plt.figure' to adjust \n",
    "# settings such as the size of the plot.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "\n",
    "plt.figure(figsize=(3,6))\n",
    "plt.boxplot([results['int_mean'], results['int_mem_mean']], \n",
    "            labels=['int_mean', 'int_mem_mean'],\n",
    "           widths=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Create a scatter plot of cell outline length over cell area\n",
    "\n",
    "# Use the function 'plt.scatter' for this. Be sure to properly label the \n",
    "# plot using 'plt.xlabel' and 'plt.ylabel'.\n",
    "# Note: it is a good idea to make the marker (the data point) more transparent so that\n",
    "# where you found the plot less transparent it means there are data points overlapping.\n",
    "### YOUR CODE HERE!\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(results[\"cell_area\"], results[\"cell_edge\"],\n",
    "           edgecolor='k', s=30, alpha=0.5)\n",
    "plt.xlabel('cell area [pxl^2]')\n",
    "plt.ylabel('cell edge length [pxl]')\n",
    "\n",
    "# BONUS: Do you understand why you are seeing the pattern this produces? \n",
    "###\n",
    "# ->> The curve reflects how circumference scales with area!\n",
    "\n",
    "# Can you generate a 'null model' curve that assumes all cells to be circular?\n",
    "### YOUR CODE HERE!\n",
    "cell_area_range = np.linspace(min(results[\"cell_area\"]), max(results[\"cell_area\"]), num = 100)\n",
    "circle_circumference = 2*np.pi*np.sqrt(cell_area_range/ np.pi)\n",
    "plt.plot(cell_area_range, circle_circumference, color='r', alpha=0.8)\n",
    "plt.legend(['circles', 'data'], loc=2, fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "# What is the result? Do you notice something odd about it? What could be the reason for\n",
    "# this and how could it be fixed?\n",
    "###\n",
    "# ->> In general, the cells don't deviate all that much from the circular case.\n",
    "# ->> Strangely, some cells have a smaller outline than the circumference of a circle\n",
    "#     of equivalent area. This is mathematically impossible.\n",
    "# ->> A possible reason could be that the measures are taken in pixels, which leads\n",
    "#     to a so-called discretization error. It could be fixed by \"meshing\" the cell\n",
    "#     outline and interpolating a more accurate measurement of circumference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iv) Perform a linear fit of membrane intensity over cell area\n",
    "\n",
    "# Use the function 'linregress' from the module 'scipy.stats'. Be sure to read the docs to\n",
    "# understand the output of this function. Print the output.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "\n",
    "# Compute linear fit\n",
    "from scipy.stats import linregress\n",
    "linfit = linregress(results[\"cell_area\"], results[\"int_mem_mean\"])\n",
    "\n",
    "# Print all the results\n",
    "linprops = ['slope', 'intercept','rvalue','pvalue', 'stderr'] #linfit properties\n",
    "for index,prop in enumerate(linprops):\n",
    "    print( prop, '\\t', '{:4.2e}'.format(linfit[index]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (v) Think about the result\n",
    "\n",
    "# Note that the fit seems to return a highly significant p-value but a very low correlation \n",
    "# coefficient (r-value). Based on prior knowledge, we would not expect a linear correlation of \n",
    "# this sort to be present in our data. \n",
    "#\n",
    "# This should prompt several questions:\n",
    "#   1) What does this p-value actually mean? Check the docs of 'linregress'!\n",
    "###\n",
    "#       ->> This p-value only means that, given a linear fit through this data, the slope of the\n",
    "#           fit is very unlikely to be zero. However, it does not make a statement on whether or\n",
    "#           not it makes sense to use a linear fit in the first place. Looking at the scatterplot\n",
    "#           below or at the correlation coefficient r, it is clear that a linear fit on this data\n",
    "#           is not meaningful.\n",
    "#       ->> Note also: With single-cell approaches, we quickly get to a large number of data points. \n",
    "#           This makes hypothesis testing in general less useful, as p-values tend to become very\n",
    "#           small even if the null hypothesis holds. It makes sense to instead report effect sizes.\n",
    "#           This is a tricky topic but well worth reading up on.\n",
    "#\n",
    "#   2) Could there be artifacts in our segmentation that bias this analysis?\n",
    "###\n",
    "#       ->> Oversegmentation is an important source of bias here. If a cell is oversegmented,\n",
    "#           it will be considered as two or three cells. These will naturally have a lower\n",
    "#           cell area and will naturally have a lower membrane intensity because some of their\n",
    "#           edges are actually not on membranes. In other words, they will fall into the bottom\n",
    "#           left of the plot, distorting the data.\n",
    "#\n",
    "# In general, it's always good to be very careful when doing any kind of data analysis. Make sure you \n",
    "# understand the functions you are using and always check for possible errors or sources of bias!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vi) Overlay the linear fit onto a scatter plot\n",
    "\n",
    "# Recall that a linear function is defined by `y = slope * x + intercept`.\n",
    "\n",
    "# To define the line you'd like to plot, you need two values of x (the starting point and\n",
    "# and the end point of the line). What values of x make sense? Can you get them automatically?\n",
    "### YOUR CODE HERE!\n",
    "#   ->> The max and min values in the data are a good choice.\n",
    "x_vals = [min(results[\"cell_area\"]), max(results[\"cell_area\"])]\n",
    "\n",
    "# When you have the x-values for the starting point and end point, get the corresponding y \n",
    "# values from the fit through the equation above.\n",
    "### YOUR CODE HERE!\n",
    "y_vals = [linfit[0] * x_vals[0] + linfit[1], linfit[0] * x_vals[1] + linfit[1]]\n",
    "\n",
    "# Plot the line with 'plt.plot'. Adjust the line's properties so it is well visible.\n",
    "# Note: Remember that you have to create the scatterplot before plotting the line so that\n",
    "#       the line will be placed on top of the scatterplot.\n",
    "### YOUR CODE HERE!\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(results[\"cell_area\"], results[\"int_mem_mean\"], \n",
    "            edgecolor='k', s=30, alpha=0.5)\n",
    "plt.plot(x_vals, y_vals, color='red', lw=2, alpha=0.8)\n",
    "\n",
    "# Use 'plt.legend' to add information about the line to the plot.\n",
    "### YOUR CODE HERE!\n",
    "plt.legend([\"linear fit, Rsq={:4.2e}\".format(linfit[2]**2.0)], frameon=False, loc=4)\n",
    "\n",
    "# Label the plot and finally show it with 'plt.show'.\n",
    "### YOUR CODE HERE!\n",
    "plt.xlabel(\"cell area [pxl]\")\n",
    "plt.ylabel(\"Mean membrane intensity [a.u.]\")\n",
    "plt.title(\"Scatterplot with linear fit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vii) Map the cell area back onto the image as a 'heatmap'\n",
    "\n",
    "# Scale the cell area data to 8bit so that it can be used as pixel intensity values.\n",
    "# Hint: if the largest cell area should correspond to the value 255 in uint8, then \n",
    "#       the other cell areas correspond to 'cell_area * 255 / largest_cell_area'.\n",
    "# Hint: To perform an operation on all cell area values at once, convert the list \n",
    "#       of cell areas to a numpy array.\n",
    "### YOUR CODE HERE!\n",
    "areas_8bit = np.array(results[\"cell_area\"]) / max(results[\"cell_area\"]) * 255\n",
    "\n",
    "# Initialize a new image array; all values should be zeros, the shape should be identical \n",
    "# to the images we worked with before and the dtype should be uint8.\n",
    "### YOUR CODE HERE!\n",
    "area_map = np.zeros_like(clean_seg, dtype = np.uint8)\n",
    "\n",
    "# Iterate over the segmented cells. In addition to the cell IDs, the for-loop should\n",
    "# also include a simple counter (starting from 0) with which the area measurement can be \n",
    "# accessed by indexing.\n",
    "### YOUR CODE HERE!\n",
    "for index, cell_id in enumerate(results[\"cell_id\"]):\n",
    "\n",
    "    # Mask the current cell and assign the cell's (re-scaled) area value to the cell's pixels.\n",
    "    ### YOUR CODE HERE!\n",
    "    area_map[clean_seg==cell_id] = areas_8bit[index]\n",
    "    \n",
    "# Visualize the result as a colored semi-transparent overlay over the raw/smoothed original input image.\n",
    "# BONUS: See if you can exclude outliers to make the color mapping more informative!\n",
    "### YOUR CODE HERE!\n",
    "\n",
    "# Mask of outliers (the largest and smallest 5% of all cells)\n",
    "outlier_mask = np.logical_or(area_map > np.percentile(areas_8bit, 95),\n",
    "                             area_map < np.percentile(areas_8bit, 5))\n",
    "\n",
    "# Mask of all regions to leave blank (outliers + image boundary cells)\n",
    "full_mask = np.logical_or(area_map==0, outlier_mask)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img, interpolation='none', cmap='gray')\n",
    "plt.imshow(np.ma.array(area_map, mask=full_mask),\n",
    "           interpolation='none', cmap='viridis', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Output to Files <a id=write></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "The final step of the pipeline shows how to write various outputs of the pipeline to files.\n",
    "\n",
    "Data can be saved to files in a human-readable format such as text files (e.g. to import into Excel), in a format readable for other programs such as tif-images (e.g. to view in Fiji) or in a language-specific file that makes it easy to reload the data into python in the future (e.g. for further analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'> Exercise </font>\n",
    "\n",
    "Write the generated data into a variety of different output files.\n",
    "\n",
    "Follow the instructions in the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Write one or more of the images you produced to a tif file\n",
    "\n",
    "# Use the function 'imsave' from the 'skimage.io' module. Make sure that the array you are \n",
    "# writing is of integer type. If necessary, you can use the method 'astype' for conversions, \n",
    "# e.g. 'some_array.astype(np.uint8)' or 'some_array.astype(np.uint16)'. Careful when \n",
    "# converting a segmentation to uint8; if there are more than 255 cells, the 8bit format\n",
    "# doesn't have sufficient bit-depth to represent all cell IDs!\n",
    "#\n",
    "# You can also try adding the segmentation to the original image, creating an image with\n",
    "# two channels, one of them being the segmentation. \n",
    "#\n",
    "# After writing the file, load it into Fiji and check that everything worked as intended.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "from skimage.io import imsave\n",
    "imsave(\"example_cells_1_edges.tif\", edges.astype(np.uint16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Write a figure to a png or pdf\n",
    "\n",
    "# Recreate the scatter plot from above (with or without the regression line), then save the figure\n",
    "# as a png using 'plt.savefig'. Alternatively, you can also save it to a pdf, which will create a\n",
    "# vector graphic that can be imported into programs like Adobe Illustrator.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "# Create plot (but don't show)\n",
    "plt.scatter(results[\"cell_area\"], results[\"int_mem_mean\"], \n",
    "            edgecolor='k', s=30, alpha=0.5)\n",
    "plt.plot(x_vals, y_vals, color='red', lw=2, alpha=0.8)\n",
    "plt.legend([\"linear fit, Rsq={:4.2e}\".format(linfit[2]**2.0)], frameon=False, loc=4)\n",
    "plt.xlabel(\"cell area [pxl]\")\n",
    "plt.ylabel(\"Mean membrane intensity [a.u.]\")\n",
    "plt.title(\"Scatterplot with linear fit\")\n",
    "\n",
    "# Save as png and pdf\n",
    "plt.savefig('example_cells_1_scatterFit.png')\n",
    "plt.savefig('example_cells_1_scatterFit.pdf')\n",
    "plt.clf()  # Clear the figure buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Save the segmentation as a numpy file\n",
    "\n",
    "# Numpy files allow fast storage and reloading of numpy arrays. Use the function 'np.save'\n",
    "# to save the array and reload it using 'np.load'.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "np.save(\"example_cells_1_seg\", clean_seg)  # Save\n",
    "seg = np.load(\"example_cells_1_seg.npy\")  # Load\n",
    "print(clean_seg.shape, seg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iv) Save the result dictionary as a pickle file\n",
    "\n",
    "# Pickling is a way of generating generic files from almost any python object, which can easily\n",
    "# be reloaded into python at a later point in time.\n",
    "# You will need to open an empty file object using 'open' in write-bytes mode ('wb'). It's best to  \n",
    "# do so using the 'with'-statement (context manager) to make sure that the file object will be \n",
    "# closed automatically when you are done with it.\n",
    "# Use the function 'pickle.dump' from the 'pickle' module to write the results to the file.\n",
    "# Hint: Refer to the python documention for input and output to understand how file objects are\n",
    "#       handled in python in general.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "import pickle\n",
    "with open('example_cells_1_results.pkl','wb') as outfile:\n",
    "    pickle.dump(results, outfile)\n",
    "\n",
    "## Note: Pickled files can be re-loaded again as follows:\n",
    "#with open('my_filename.pkl', 'rb') as infile:\n",
    "#    reloaded = pickle.load(infile)\n",
    "with open('example_cells_1_results.pkl', 'rb') as infile:\n",
    "    results_reloaded = pickle.load(infile)\n",
    "    print(results_reloaded.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (v) Write a tab-separated text file of the results dict\n",
    "\n",
    "# The most generic way of saving numeric results is a simple text file. It can be imported into \n",
    "# pretty much any other program.\n",
    "\n",
    "# To write normal text files, open an empty file object in write mode ('w') using the 'with'-statement.\n",
    "### YOUR CODE HERE!\n",
    "with open('example_cells_1_results.txt','w') as outfile:\n",
    "    # Use the 'file_object.write(string)' method to write strings to the file, one line at a time,\n",
    "    # First, write the header of the data (the result dict keys), separated by tabs ('\\t'). \n",
    "    # It makes sense to first generate a complete string with all the headers and then write this \n",
    "    # string to the file as one line. Note that you will need to explicitly write 'newline' characters \n",
    "    # ('\\n') at the end of the line to switch to the next line.\n",
    "    # Hint: the string method 'join' is very useful here!\n",
    "    ### YOUR CODE HERE!\n",
    "    header_string = '\\t'.join(results.keys()) + '\\n'\n",
    "    outfile.write(header_string)\n",
    "    \n",
    "    # After writing the headers, iterate over all the cells and write the result data to the file line\n",
    "    # by line, by creating strings similar to the header string.\n",
    "    ### YOUR CODE HERE!\n",
    "    for index in range(len(results['cell_id'])):\n",
    "        data_string = '\\t'.join([str(results[key][index]) for key in results.keys()]) + '\\n'\n",
    "        outfile.write(data_string)\n",
    "\n",
    "# After writing the data, have a look at the output file in a text editor or in a spreadsheet\n",
    "# program like Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\**BONUS\\** >> Batch Processing <a id=batch></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "In practice, we never work with just a single image, so we would like to make it possible to run our analysis pipeline for multiple images and then collect and analyze all the results. This final section of the tutorial shows how to do just that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='teal'>Exercise</font>\n",
    "\n",
    "To run a pipeline multiple times, it needs to be packaged into a function or - even better - as a separate module. Jupyter notebook is not well suited for this, so if you're working in a notebook, first extract your code to a `.py` file (see instructions below). If you are not working in a notebook, create a copy of your pipeline; we will modify this copy into a function that can then be called repeatedly for different images.\n",
    "\n",
    "To export a jupyter notebook as a `.py` file, use `File > Download as > Python (.py)`, then save the file. Open the resulting python script in a text editor or in an IDE like PyCharm. \n",
    "\n",
    "\n",
    "#### Let's clean the script a bit:\n",
    "\n",
    "- Remove the line `%matplotlib [inline|notebook|qt]`. It is not valid python code outside of a Jupyter notebook.\n",
    "\n",
    "\n",
    "- Go through the script and comment out everything related to plotting; when running a pipeline for dozens or hundreds of images, we usually do not want to generate tons of plots. Similarly, it can make sense to remove some print statments if you have many of them.\n",
    "\n",
    "\n",
    "- Remove the sections `Manual Thresholding` and `Connected Components Labeling`; they are not used in the final segmentation.\n",
    "\n",
    "\n",
    "- Remove the sections `Simple Analysis and Visualization` and `Writing Output to Files`; we will collect the output for each image when running the pipeline in a loop. That way, everything can be analyzed at once at the end. \n",
    "    - Note that, even though we skip it here, it is often very useful to store every input file's corresponding outputs in new files. When doing so, the output files should use the name of the input file modified with an additional suffix. For example, the results extracted when analyzing `img_1.tif` might best be stored as `img_1_results.pkl`.\n",
    "    - You can implement this approach for saving the segmentations and/or the result dicts as a *bonus* exercise!\n",
    "\n",
    "\n",
    "- Feel free to delete some of the background information to make the script more concise.\n",
    "\n",
    "\n",
    "#### Converting the pipeline to a function:\n",
    "\n",
    "Convert the entire pipeline into a function that accepts a directory and a filename as input, runs everything, and returns the final segmentation and the results dictionary. To do this, you must:\n",
    "\n",
    "- Add the function definition statement at the beginning of the script (after the imports)\n",
    "- Replace the 'hard-coded' directory path and filename by variables that are accepted by the function\n",
    "- Indent all the code\n",
    "- Add a return statement at the end\n",
    "\n",
    "\n",
    "#### Importing the function and running it for multiple input files:\n",
    "\n",
    "To actually run the pipeline function for multiple input files, we need to do the following:\n",
    "\n",
    "- Import the pipeline function from the `.py` file\n",
    "- Iterate over all the filenames in a directory\n",
    "- For each filename, call the pipeline function\n",
    "- Collect the returned results\n",
    "\n",
    "Once you have converted your pipeline into a function as described above, you can import and run it according to the instructions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution Note\n",
    "\n",
    "The converted version of the pipeline can be found in `batch_processing_solution.py`. \n",
    "\n",
    "Note that the most of the exercise comments have been removed so it doesn't look too cluttered. However, this level of clean-up is probably a bit extreme; it is generally recommended to retain at least basic comments on the purpose of each code block. \n",
    "\n",
    "Also note that a doc string was added to the function definition (the string designated with three `\"\"\"` at the start and end, directly under the function definition). This is a very useful reference, since it is automatically recognized as a help message by Jupyter notebook (and other IDEs), so you can easily double-check what an imported function does, for example by typing `run_pipeline?` in a code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Test if your pipeline function actually works\n",
    "\n",
    "# Import your function using the normal python syntax for imports, like this:\n",
    "#   from your_module import your_function\n",
    "# Run the function and visualize the resulting segmentation. Make sure everything works as intended.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "from batch_processing_solution import run_pipeline\n",
    "pip_seg, pip_results = run_pipeline(r\"example_data\", r'example_cells_1.tif')\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(np.zeros_like(pip_seg), interpolation='none', cmap='gray', vmax=1)  # Simple black background\n",
    "plt.imshow(np.ma.array(pip_seg, mask=pip_seg==0), interpolation='none', cmap='prism')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (ii) Get all relevant filenames from the input directory\n",
    "\n",
    "# Use the function 'listdir' from the module 'os' to get a list of all the files\n",
    "# in a directory. Find a way to filter out only the relevant input files, namely\n",
    "# \"example_cells_1.tif\" and \"example_cells_2.tif\". Of course, one would usually\n",
    "# do this for many more images, otherwise it's not worth the effort.\n",
    "# Hint: Loop over the filenames and use if statements to decide which ones to \n",
    "#       keep and which ones to throw away.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "# Get all files\n",
    "dirpath = r\"example_data\"\n",
    "from os import listdir\n",
    "filelist = listdir(dirpath)\n",
    "\n",
    "# Filter for target files: simple option\n",
    "# Note that this will use ALL files with a .tif ending, which in some circumstances\n",
    "# may include files that are not supposed to be used!\n",
    "target_files = []\n",
    "for fname in filelist:\n",
    "    if fname.endswith('.tif'):\n",
    "        target_files.append(fname)\n",
    "print(target_files)\n",
    "\n",
    "# Filter for target files: advanced option using regex and a list comprehension\n",
    "import re\n",
    "target_pattern = re.compile(\"^example_cells_\\d+\\.tif$\")\n",
    "target_files = [fname for fname in filelist if target_pattern.match(fname)]\n",
    "print(target_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iii) Iterate over the input filenames and run the pipeline function\n",
    "\n",
    "# Be sure to collect the output of the pipeline function in a way that allows\n",
    "# you to trace it back to the file it came from. You could for example use a\n",
    "# dictionary with the filenames as keys.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "# Initialize empty dictionaries\n",
    "all_seg = {}\n",
    "all_results = {}\n",
    "\n",
    "# Iterate over files and run pipeline for each\n",
    "for fname in target_files:\n",
    "    pip_seg, pip_results = run_pipeline(dirpath, fname)\n",
    "    all_seg[fname] = pip_seg\n",
    "    all_results[fname] = pip_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (iv) Recreate one of the scatterplots from above but this time with all the cells\n",
    "\n",
    "# You can color-code the dots to indicate which file they came from. Don't forget to\n",
    "# add a corresponding legend.\n",
    "\n",
    "### YOUR CODE HERE!\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "colors = ['blue','red']\n",
    "for key, color in zip(sorted(all_results.keys()), colors):\n",
    "    plt.scatter(all_results[key][\"cell_area\"], all_results[key][\"cell_edge\"],\n",
    "                edgecolor='k', c=color, s=30, alpha=0.5, label=key)\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel(\"cell area [pxl^2]\")\n",
    "plt.ylabel(\"cell edge length [pxl]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='teal'>*Congratulations! You have completed the tutorial!*</font>\n",
    "\n",
    "**We hope you enjoyed the ride and learned a lot!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concluding Remarks\n",
    "\n",
    "It's important to remember that the phrase ***\"Use it or loose it!\"*** fully applies for the skills taught in this tutorial.\n",
    "\n",
    "If you now just go back to the lab and don't touch python or image analysis for the next half year, most of the things you have learned here will be lost.\n",
    "\n",
    "So, what can you do?\n",
    "\n",
    "\n",
    "- If possible, start applying what you have learned to your own work right away\n",
    "\n",
    "\n",
    "- Even if your current work doesn't absolutely *need* coding / image analysis (which to be honest is hard to believe! ;p), you can still use it at least to make some nice plots!\n",
    "\n",
    "\n",
    "- Another very good approach is to find yourself an interesting little side project you can play around with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We wish you the best of luck for all your coding endeavors!***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
